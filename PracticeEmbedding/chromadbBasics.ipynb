{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ğŸ”¹ 1. **Vector Embedding**\n",
        "\n",
        "### âœ… What is it?\n",
        "\n",
        "It's a way to represent words or data as **vectors (lists of numbers)** so that machines can understand and compare them.\n",
        "\n",
        "### âœ… Why use it?\n",
        "\n",
        "Because machines can't understand text like \"cat\" or \"banana\"â€”but they can understand numbers.\n",
        "\n",
        "### âœ… Example:\n",
        "\n",
        "| Word   | Vector Embedding (shortened) |\n",
        "| ------ | ---------------------------- |\n",
        "| cat    | `[0.2, 0.8, 0.4]`            |\n",
        "| dog    | `[0.22, 0.79, 0.38]`         |\n",
        "| banana | `[0.9, 0.1, 0.7]`            |\n",
        "\n",
        "* \"cat\" and \"dog\" are similar (vectors are close)\n",
        "* \"cat\" and \"banana\" are different (vectors are far)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 2. **Word2Vec**\n",
        "\n",
        "### âœ… What is it?\n",
        "\n",
        "A model that learns word embeddings based on **context** (surrounding words).\n",
        "\n",
        "### âœ… Two Types:\n",
        "\n",
        "* **CBOW (Continuous Bag of Words)** â€“ predicts word from context.\n",
        "* **Skip-gram** â€“ predicts context from a word.\n",
        "\n",
        "### âœ… Example:\n",
        "\n",
        "Training sentence: â€œThe cat sits on the mat.â€\n",
        "\n",
        "* Word2Vec learns:\n",
        "\n",
        "  * \"cat\" is often near \"dog\"\n",
        "  * So their vectors will be similar\n",
        "\n",
        "**Resulting Vectors:**\n",
        "\n",
        "* cat â†’ `[0.25, 0.8, 0.15]`\n",
        "* dog â†’ `[0.26, 0.81, 0.14]`\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 3. **GloVe (Global Vectors for Word Representation)**\n",
        "\n",
        "### âœ… What is it?\n",
        "\n",
        "Like Word2Vec, but uses **word co-occurrence** (how often words appear together in a big dataset) rather than predicting words.\n",
        "\n",
        "### âœ… Example:\n",
        "\n",
        "If â€œcatâ€ appears near â€œpetâ€, â€œfurâ€, and â€œanimalâ€ frequently, GloVe will capture that in its vector.\n",
        "\n",
        "* cat â†’ `[0.3, 0.7, 0.2]`\n",
        "* fur â†’ `[0.28, 0.68, 0.25]`\n",
        "\n",
        "### âœ… Main Difference:\n",
        "\n",
        "| Feature     | Word2Vec        | GloVe              |\n",
        "| ----------- | --------------- | ------------------ |\n",
        "| Learns from | Word context    | Word co-occurrence |\n",
        "| Training    | Predictive      | Count-based        |\n",
        "| Output      | Word embeddings | Word embeddings    |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 4. **OpenAI Embeddings**\n",
        "\n",
        "### âœ… What is it?\n",
        "\n",
        "Embeddings generated using OpenAI models like **text-embedding-ada-002**.\n",
        "\n",
        "* Works not just for **single words**, but for **full sentences**, **paragraphs**, or **documents**.\n",
        "* Very powerful and **context-aware**.\n",
        "\n",
        "### âœ… Example:\n",
        "\n",
        "Input:\n",
        "\n",
        "* â€œA cat is sleeping on the couch.â€\n",
        "* â€œA dog is lying on the sofa.â€\n",
        "\n",
        "These will get similar vectors.\n",
        "\n",
        "**Output Vector:**\n",
        "\n",
        "* 1536-dimension vector like:\n",
        "  `[0.001, -0.012, ..., 0.034]`\n",
        "\n",
        "### âœ… Use Cases:\n",
        "\n",
        "* Semantic search\n",
        "* Question-answering\n",
        "* Document similarity\n",
        "* Chatbots\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¸ Summary\n",
        "\n",
        "| Model            | Learns from                 | Input Type     | Output       | Best For                        |\n",
        "| ---------------- | --------------------------- | -------------- | ------------ | ------------------------------- |\n",
        "| Vector Embedding | General concept             | Any data       | Vectors      | Machine understanding           |\n",
        "| Word2Vec         | Context (predictive)        | Words          | Word vectors | Word similarity                 |\n",
        "| GloVe            | Word co-occurrence (counts) | Words          | Word vectors | Word similarity                 |\n",
        "| OpenAI Embedding | Deep language model         | Text/sentences | Long vectors | Semantic search, Q\\&A, chatbots |\n",
        "\n"
      ],
      "metadata": {
        "id": "Aya0wRAqwHav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **Cosine Similarity**\n",
        "2. **Embeddings for**:\n",
        "\n",
        "   * Image\n",
        "   * Text\n",
        "   * Document\n",
        "   * Graph\n",
        "   * Audio\n",
        "   * Anomaly Detection\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… 1. **Cosine Similarity**\n",
        "\n",
        "### ğŸ“Œ Definition:\n",
        "\n",
        "Cosine similarity measures the **angle** between two vectors. It tells us **how similar** the direction of the vectors is, regardless of their size.\n",
        "\n",
        "### ğŸ“Œ Formula:\n",
        "\n",
        "$$\n",
        "\\text{Cosine Similarity} = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}\n",
        "$$\n",
        "\n",
        "* `A Â· B` = dot product of vectors\n",
        "* `â€–Aâ€–` = magnitude of vector A\n",
        "* Value range:\n",
        "\n",
        "  * `1` â†’ exactly similar\n",
        "  * `0` â†’ unrelated\n",
        "  * `-1` â†’ opposite meaning\n",
        "\n",
        "### ğŸ“Œ Example:\n",
        "\n",
        "Vectors:\n",
        "\n",
        "* A = `[1, 0]`, B = `[0.9, 0.1]`\n",
        "  â†’ Cosine similarity â‰ˆ 0.99 (very similar)\n",
        "\n",
        "### ğŸ“Œ Use Cases:\n",
        "\n",
        "* Text similarity (e.g., FAQ matching)\n",
        "* Duplicate document detection\n",
        "* Image & audio embedding comparison\n",
        "* Outlier detection via distance\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… 2. **Embeddings by Data Type**\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ **A. Text Embeddings**\n",
        "\n",
        "#### ğŸ“Œ What:\n",
        "\n",
        "Turns sentences or words into vectors capturing **semantic meaning**.\n",
        "\n",
        "#### ğŸ“Œ Models:\n",
        "\n",
        "* Word2Vec, GloVe â†’ word-level\n",
        "* BERT, SBERT, OpenAI â†’ sentence-level\n",
        "\n",
        "#### ğŸ“Œ Use Cases:\n",
        "\n",
        "* Semantic search\n",
        "* Chatbots\n",
        "* Text classification\n",
        "\n",
        "#### ğŸ“Œ Example:\n",
        "\n",
        "\"Apple is tasty\" vs \"Fruit is delicious\"\n",
        "â†’ Vectors will be **close** using OpenAI or BERT.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“„ **B. Document Embeddings**\n",
        "\n",
        "#### ğŸ“Œ What:\n",
        "\n",
        "Vector representations of **full documents** or **paragraphs**.\n",
        "\n",
        "#### ğŸ“Œ Models:\n",
        "\n",
        "* OpenAI (text-embedding-ada-002)\n",
        "* SBERT, Doc2Vec\n",
        "\n",
        "#### ğŸ“Œ Use Cases:\n",
        "\n",
        "* Document clustering\n",
        "* Retrieval in QA systems\n",
        "* Duplicate detection\n",
        "\n",
        "#### ğŸ“Œ Example:\n",
        "\n",
        "Legal contract A â‰ˆ Legal contract B â†’ High cosine similarity\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ–¼ï¸ **C. Image Embeddings**\n",
        "\n",
        "#### ğŸ“Œ What:\n",
        "\n",
        "Represents visual content as vectors.\n",
        "\n",
        "#### ğŸ“Œ Models:\n",
        "\n",
        "* **CLIP** (OpenAI): Image + text alignment\n",
        "* ResNet, ViT: Feature extraction\n",
        "\n",
        "#### ğŸ“Œ Use Cases:\n",
        "\n",
        "* Image search\n",
        "* Face recognition\n",
        "* Captioning\n",
        "\n",
        "#### ğŸ“Œ Example:\n",
        "\n",
        "Two images of dogs â†’ similar embedding vectors â†’ cosine similarity â‰ˆ 1\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“Š **D. Graph Embeddings**\n",
        "\n",
        "#### ğŸ“Œ What:\n",
        "\n",
        "Represents nodes, edges, or entire graphs as vectors.\n",
        "\n",
        "#### ğŸ“Œ Models:\n",
        "\n",
        "* Node2Vec, DeepWalk, GraphSAGE, GAT\n",
        "\n",
        "#### ğŸ“Œ Use Cases:\n",
        "\n",
        "* Node classification\n",
        "* Link prediction\n",
        "* Community detection\n",
        "\n",
        "#### ğŸ“Œ Example:\n",
        "\n",
        "Users with similar connections â†’ similar embeddings â†’ recommend friends\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”‰ **E. Audio Embeddings**\n",
        "\n",
        "#### ğŸ“Œ What:\n",
        "\n",
        "Represents audio clips as vectors capturing **sound features**.\n",
        "\n",
        "#### ğŸ“Œ Models:\n",
        "\n",
        "* OpenL3\n",
        "* YAMNet (Google)\n",
        "* Wav2Vec\n",
        "\n",
        "#### ğŸ“Œ Use Cases:\n",
        "\n",
        "* Sound classification\n",
        "* Speaker verification\n",
        "* Emotion detection\n",
        "\n",
        "#### ğŸ“Œ Example:\n",
        "\n",
        "Clip of dog barking vs another â†’ cosine similarity â‰ˆ high\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸš¨ **F. Anomaly Detection Using Embeddings**\n",
        "\n",
        "#### ğŸ“Œ What:\n",
        "\n",
        "Detects unusual patterns by comparing embeddings of new data to â€œnormalâ€ data.\n",
        "\n",
        "#### ğŸ“Œ How:\n",
        "\n",
        "* Compute embedding for input\n",
        "* Compare with typical embeddings (via cosine similarity or distance)\n",
        "* Flag if too different\n",
        "\n",
        "#### ğŸ“Œ Use Cases:\n",
        "\n",
        "* Fraud detection\n",
        "* Cybersecurity\n",
        "* Fault detection in logs or systems\n",
        "\n",
        "#### ğŸ“Œ Example:\n",
        "\n",
        "Normal API request log â†’ Similar embeddings\n",
        "Weird request â†’ Dissimilar embedding â†’ Flag as anomaly\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Interview Quick Notes (Summary Table)\n",
        "\n",
        "| Data Type | Model(s) Used                 | Task                        | Similarity Metric  |\n",
        "| --------- | ----------------------------- | --------------------------- | ------------------ |\n",
        "| Text      | Word2Vec, GloVe, BERT, OpenAI | Semantic search, NLP        | Cosine Similarity  |\n",
        "| Document  | SBERT, OpenAI, Doc2Vec        | Retrieval, comparison       | Cosine / Euclidean |\n",
        "| Image     | CLIP, ResNet, ViT             | Vision search, captioning   | Cosine / Dot Prod  |\n",
        "| Graph     | Node2Vec, GraphSAGE           | Social links, fraud         | Cosine / Euclidean |\n",
        "| Audio     | Wav2Vec, OpenL3, YAMNet       | Sound detection, speaker ID | Cosine             |\n",
        "| Anomaly   | Any + outlier logic           | Detect abnormal behavior    | Cosine / Threshold |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ltNBgzH5wOnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "http://docs.trychroma.com/docs/overview/introduction\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **1. What is a \"vec embed\" (vector embedding)?**\n",
        "\n",
        "**Vector embedding** (sometimes shortened as **vec embed**) is a way to represent complex data (like text, images, or audio) as **numbers in a high-dimensional space**, so that machines (like AI models) can understand and work with them efficiently.\n",
        "\n",
        "For example, the word **\"king\"** might be embedded as a vector like:\n",
        "\n",
        "```\n",
        "[0.21, -0.14, 0.57, ..., 0.09]  â† (a list of numbers)\n",
        "```\n",
        "\n",
        "These vectors capture the **semantic meaning** of the data. For instance:\n",
        "\n",
        "* \"king\" and \"queen\" will have similar vectors.\n",
        "* Texts with similar meaning will have embeddings that are close together in vector space.\n",
        "\n",
        "Embeddings are used in:\n",
        "\n",
        "* Search engines\n",
        "* Chatbots\n",
        "* Recommendation systems\n",
        "* Clustering and classification tasks\n",
        "\n",
        "Popular embedding models:\n",
        "\n",
        "* OpenAI Embeddings (like `text-embedding-3-small`)\n",
        "* Hugging Face models (e.g., Sentence-BERT)\n",
        "\n",
        "---\n",
        "\n",
        "### **2. What is ChromaDB?**\n",
        "\n",
        "**ChromaDB** is an **open-source vector database**. It stores and searches through vector embeddings efficiently.\n",
        "\n",
        "Key purposes:\n",
        "\n",
        "* Save a large collection of text/image embeddings.\n",
        "* Perform fast **similarity searches** (like finding texts most similar to a user query).\n",
        "* Used in **RAG (Retrieval-Augmented Generation)** systems where an AI chatbot retrieves relevant documents to enhance answers.\n",
        "\n",
        "Features:\n",
        "\n",
        "* Supports metadata (like tags or file info).\n",
        "* Has a Python API and can run in-memory or persist to disk.\n",
        "* Works well with tools like LangChain, LlamaIndex, and OpenAI.\n",
        "\n",
        "---\n",
        "\n",
        "### **In practice**:\n",
        "\n",
        "You often:\n",
        "\n",
        "1. Use a model to convert your documents into **vector embeddings**.\n",
        "2. Store those in **ChromaDB**.\n",
        "3. Later, when a user asks a question, you:\n",
        "\n",
        "   * Convert the question into a vector.\n",
        "   * Use ChromaDB to **find similar vectors** (relevant documents).\n",
        "   * Feed those documents into an AI model to answer the question.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7wZfIgqtwh0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssvmhRMMwMkX",
        "outputId": "6efb9f1e-f117-4e5c-8c67-39e76f4b8dc4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.1)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.73.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.0)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.33.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=85ef54c21ccecfa2806d9fd1e231f7e6c2efc9c521772e7204b440fb713c0864\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, python-dotenv, pybase64, overrides, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.1.0 onnxruntime-1.22.1 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.1 pypika-0.48.9 python-dotenv-1.1.1 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import chromadb"
      ],
      "metadata": {
        "id": "xHCLAjEjCvZU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "chroma_client = chromadb.Client()\n"
      ],
      "metadata": {
        "id": "c_ndmcZ7DXDg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection = chroma_client.create_collection(name=\"collectionz\")"
      ],
      "metadata": {
        "id": "ZQV0Ww_HDfBG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great question! Let's break this down **both practically and theoretically**. You're using `collection.add()` (from **ChromaDB**) to insert documents. Hereâ€™s a deep dive into whatâ€™s happening **under the hood**.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ” **Your Code**\n",
        "\n",
        "```python\n",
        "collection.add(\n",
        "    ids=[\"id1\", \"id2\"],\n",
        "    documents=[\n",
        "        \"This is a document about pineapple\",\n",
        "        \"This is a document about oranges\"\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "You're adding two documents with IDs to a ChromaDB collection. ChromaDB will store and index these documents using **vector embeddings**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ What Happens in the Background?\n",
        "\n",
        "### **1. Embedding Generation**\n",
        "\n",
        "When you call `collection.add(documents=[...])`, ChromaDB either:\n",
        "\n",
        "* Uses a **default embedding model**, or\n",
        "* You provide your own embeddings (via the `embeddings` parameter).\n",
        "\n",
        "For example, the sentence `\"This is a document about pineapple\"` might be turned into a vector like:\n",
        "\n",
        "```\n",
        "[0.12, 0.35, ..., 0.92]  â† (e.g. 384-dimensional float vector)\n",
        "```\n",
        "\n",
        "This is called an **embedding**. It captures the **meaning** of the sentence in a numerical form.\n",
        "\n",
        "These embeddings are generated by **transformer models** like:\n",
        "\n",
        "* Sentence-BERT\n",
        "* OpenAIâ€™s `text-embedding-3-small`\n",
        "* Instructor or MiniLM models\n",
        "\n",
        "This step is key: **text â†’ vector space**\n",
        "\n",
        "---\n",
        "\n",
        "### **2. ID Assignment**\n",
        "\n",
        "Each document is assigned a unique ID (`\"id1\"`, `\"id2\"`) for future retrieval, deletion, or updates.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Storage in Vector Index**\n",
        "\n",
        "Now, ChromaDB:\n",
        "\n",
        "* Stores the document string\n",
        "* Stores its vector embedding\n",
        "* Stores its ID\n",
        "* Optionally stores **metadata** (if you give it)\n",
        "\n",
        "All of this is indexed in its internal **vector index** (usually something like FAISS, HNSW, or custom in-memory index).\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Vector Indexing & Similarity**\n",
        "\n",
        "ChromaDB indexes embeddings to support **fast similarity search**.\n",
        "\n",
        "When you later call something like:\n",
        "\n",
        "```python\n",
        "collection.query(query_texts=[\"tell me about fruit\"])\n",
        "```\n",
        "\n",
        "Chroma will:\n",
        "\n",
        "* Convert `\"tell me about fruit\"` into a query embedding\n",
        "* Compare it to all stored document vectors\n",
        "* Use **cosine similarity** or **Euclidean distance** to find the most relevant ones\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Theory Behind It All\n",
        "\n",
        "### **1. Vector Embeddings (Semantic Space)**\n",
        "\n",
        "Embeddings map **text into a vector space** where:\n",
        "\n",
        "* Semantically similar texts are **close together**\n",
        "* Unrelated texts are **far apart**\n",
        "\n",
        "E.g.:\n",
        "\n",
        "* `\"pineapple\"` is close to `\"mango\"`\n",
        "* Far from `\"car engine\"`\n",
        "\n",
        "This is often done using pre-trained transformer models trained on **contrastive learning** or **masked language modeling**.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Similarity Search**\n",
        "\n",
        "You use **vector similarity search** to:\n",
        "\n",
        "* Find the closest documents to a given query vector\n",
        "* This is the backbone of **Retrieval-Augmented Generation (RAG)**\n",
        "\n",
        "Common similarity metrics:\n",
        "\n",
        "* **Cosine similarity** (angle between vectors)\n",
        "* **Dot product**\n",
        "* **Euclidean distance**\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Vector Indexing Algorithms**\n",
        "\n",
        "To speed up search, ChromaDB may use:\n",
        "\n",
        "* **FAISS** (Facebook AI Similarity Search)\n",
        "* **HNSW** (Hierarchical Navigable Small World Graph)\n",
        "* **Approximate Nearest Neighbor (ANN)** algorithms\n",
        "\n",
        "These allow it to search **millions of embeddings quickly**.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’¡ Summary of What Your Code Does\n",
        "\n",
        "| Step | Action                                                                       |\n",
        "| ---- | ---------------------------------------------------------------------------- |\n",
        "| 1    | Documents are converted into **embeddings** using a model                    |\n",
        "| 2    | Each doc is stored with its **ID**, **embedding**, and optional **metadata** |\n",
        "| 3    | Embeddings are added to a **vector index** for fast similarity search        |\n",
        "| 4    | Enables you to later **search, retrieve, or delete** these documents easily  |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RkDrcdE4G9Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection.add(\n",
        "    ids=[\"id1\", \"id2\"],\n",
        "    documents=[\n",
        "        \"Daily high temperatures for Tokyo, Japan from 1999â€“2024.\",\n",
        "        \"Lines of code in a large software project\"\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "V_3voLiZFVKl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = collection.query(\n",
        "    query_texts=[\"python is easy\"], # Chroma will embed this for you\n",
        "    n_results=1 # how many results to return\n",
        ")\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGdRj1ELHK2l",
        "outputId": "026d0ffe-bb43-4a94-83ca-57a695a5ec58"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [['id2']], 'embeddings': None, 'documents': [['Lines of code in a large software project']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None]], 'distances': [[1.5293580293655396]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = collection.query(\n",
        "    query_texts=[\"python is in east asia\"], # Chroma will embed this for you\n",
        "    n_results=1 # how many results to return\n",
        ")\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkyAtwC8HQNh",
        "outputId": "2afbae92-aeba-4435-c323-bcbfee688a4b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [['id1']], 'embeddings': None, 'documents': [['Daily high temperatures for Tokyo, Japan from 1999â€“2024.']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None]], 'distances': [[1.6916242837905884]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Detailed Notes on `.query()` Parameters & Returned Result Structure in ChromaDB\n",
        "\n",
        "---\n",
        "\n",
        "## 1. **`query_texts`**\n",
        "\n",
        "* **Type:** `List[str]`\n",
        "* **Description:**\n",
        "  List of query strings you want to search for in the collection.\n",
        "  Each string is embedded internally into a vector and compared against stored document embeddings.\n",
        "* **Example:**\n",
        "\n",
        "  ```python\n",
        "  query_texts=[\"python programming\", \"tropical fruits\"]\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "## 2. **`n_results`**\n",
        "\n",
        "* **Type:** `int`\n",
        "* **Description:**\n",
        "  How many top results to return *per query*.\n",
        "  If you provide 2 queries and `n_results=3`, you get 3 results for each query (total 6).\n",
        "* **Default:** `1`\n",
        "* **Example:**\n",
        "\n",
        "  ```python\n",
        "  n_results=3\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "## 3. **`where`**\n",
        "\n",
        "* **Type:** `Dict[str, Any]`\n",
        "* **Description:**\n",
        "  Filters search results **based on document metadata**. You can use this to restrict the query to documents that match certain key-value metadata pairs.\n",
        "* **Example:**\n",
        "  Suppose documents have a `category` metadata field, to find only documents where `\"category\" == \"tech\"`:\n",
        "\n",
        "  ```python\n",
        "  where={\"category\": \"tech\"}\n",
        "  ```\n",
        "* **How it works:**\n",
        "  Documents without the matching metadata are excluded from the search space before similarity scoring.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. **`where_document`**\n",
        "\n",
        "* **Type:** `Dict[str, Any]`\n",
        "* **Description:**\n",
        "  Filters documents by applying constraints on the **document content itself** (the raw text).\n",
        "  You can do substring matching or other filters supported by the underlying database.\n",
        "* **Example:**\n",
        "  To return only documents containing the word `\"python\"`:\n",
        "\n",
        "  ```python\n",
        "  where_document={\"$contains\": \"python\"}\n",
        "  ```\n",
        "* **Use case:**\n",
        "  Useful if you want to combine vector search with keyword filtering.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. **`include`**\n",
        "\n",
        "* **Type:** `List[str]`\n",
        "* **Description:**\n",
        "  Specifies which fields to return in the results.\n",
        "* **Typical fields:**\n",
        "\n",
        "  * `\"ids\"` â€” Return the IDs of matching documents\n",
        "  * `\"documents\"` â€” Return the original document text\n",
        "  * `\"distances\"` â€” Return similarity scores or distances\n",
        "  * `\"metadatas\"` â€” Return metadata\n",
        "* **Example:**\n",
        "  Return only documents and distances, no IDs:\n",
        "\n",
        "  ```python\n",
        "  include=[\"documents\", \"distances\"]\n",
        "  ```\n",
        "* **Benefit:**\n",
        "  Reduces payload size if you donâ€™t need everything.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. **`offset`**\n",
        "\n",
        "* **Type:** `int`\n",
        "* **Description:**\n",
        "  Skip the first `offset` matches, useful for pagination.\n",
        "* **Example:**\n",
        "  To get results starting from the 5th closest:\n",
        "\n",
        "  ```python\n",
        "  offset=4\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "## 7. **`query_embeddings`** *(Optional)*\n",
        "\n",
        "* **Type:** `List[List[float]]`\n",
        "* **Description:**\n",
        "  Instead of passing raw text strings in `query_texts`, you can directly provide **precomputed embeddings**. This is useful if you want to use your own embedding model or cache embeddings.\n",
        "* **Note:**\n",
        "  If you provide this, **do not** provide `query_texts`.\n",
        "\n",
        "\n",
        "\n",
        "## Explanation of Each Field\n",
        "\n",
        "| Field       | Description                                              | Data Type                    |\n",
        "| ----------- | -------------------------------------------------------- | ---------------------------- |\n",
        "| `ids`       | List of document IDs returned for each query             | `List[List[str]]`            |\n",
        "| `documents` | List of original document text returned for each query   | `List[List[str]]`            |\n",
        "| `distances` | List of similarity scores or distances for each match    | `List[List[float]]`          |\n",
        "| `metadatas` | List of metadata dicts associated with each returned doc | `List[List[Dict[str, Any]]]` |\n",
        "\n",
        "* Each outer list corresponds to the queries in `query_texts`.\n",
        "* Each inner list contains the top `n_results` matches for that query.\n",
        "\n",
        "---\n",
        "\n",
        "## What does the `distances` value mean?\n",
        "\n",
        "* Usually a **lower distance means a closer match** (Euclidean distance).\n",
        "* If cosine similarity is used, **higher scores** mean closer.\n",
        "* The exact meaning depends on the embedding and search index settings.\n",
        "* Use `distances` to rank confidence or filter low-quality matches.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Summary Table of `.query()` params\n",
        "\n",
        "| Parameter          | Purpose                                     | Example                              |\n",
        "| ------------------ | ------------------------------------------- | ------------------------------------ |\n",
        "| `query_texts`      | List of queries to embed and search         | `[\"python\", \"fruit\"]`                |\n",
        "| `n_results`        | Number of top matches per query             | `n_results=3`                        |\n",
        "| `where`            | Filter by document metadata key-values      | `{\"category\": \"tech\"}`               |\n",
        "| `where_document`   | Filter by text content inside documents     | `{\"$contains\": \"python\"}`            |\n",
        "| `include`          | Fields to return (ids, documents, etc.)     | `[\"documents\", \"distances\"]`         |\n",
        "| `offset`           | Skip first N results (pagination)           | `offset=5`                           |\n",
        "| `query_embeddings` | Provide your own embeddings instead of text | `[[0.1, 0.2, ...], [0.3, 0.4, ...]]` |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Cg1sSpGtYqSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# Embedding Functions â€” Easy & Detailed Notes\n",
        "\n",
        "---\n",
        "\n",
        "## What is an Embedding Function?\n",
        "\n",
        "An **embedding function** is a process (usually a machine learning model) that **converts data (text, images, etc.) into vectors (arrays of numbers)**.\n",
        "\n",
        "* Input: Something like a sentence, word, or image\n",
        "* Output: A fixed-length numeric vector (e.g., `[0.12, -0.34, 0.56, ...]`)\n",
        "\n",
        "These vectors represent the **meaning or features** of the input in a way that computers can compare and analyze mathematically.\n",
        "\n",
        "---\n",
        "\n",
        "## Why do we need Embedding Functions?\n",
        "\n",
        "* Computers donâ€™t understand raw text or images naturally.\n",
        "* We want to compare data by meaning, not just exact words.\n",
        "* Embeddings let us measure **semantic similarity** between items:\n",
        "\n",
        "  * â€œappleâ€ and â€œfruitâ€ will have vectors close together.\n",
        "  * â€œappleâ€ and â€œcarâ€ will be far apart.\n",
        "* Enables powerful tasks like:\n",
        "\n",
        "  * Semantic search\n",
        "  * Recommendation systems\n",
        "  * Clustering and classification\n",
        "  * Conversational AI\n",
        "\n",
        "---\n",
        "\n",
        "## How does an Embedding Function work?\n",
        "\n",
        "### Intuition:\n",
        "\n",
        "* The function is a **neural network model** trained on huge datasets.\n",
        "* It learns to map inputs with similar meanings close together in vector space.\n",
        "* Example: Sentence-BERT, OpenAIâ€™s text embeddings, CLIP for images.\n",
        "\n",
        "### Technical side:\n",
        "\n",
        "* Input text is tokenized (split into pieces).\n",
        "* The tokens pass through layers of the model.\n",
        "* The final layer outputs a vector embedding.\n",
        "\n",
        "---\n",
        "\n",
        "## Examples of Embedding Functions\n",
        "\n",
        "### Text Embeddings:\n",
        "\n",
        "* **OpenAI embeddings**: `text-embedding-3-small`\n",
        "* **Sentence-BERT** (SBERT): Great for sentences, paragraphs\n",
        "* **Universal Sentence Encoder** (USE)\n",
        "\n",
        "### Image Embeddings:\n",
        "\n",
        "* **CLIP model**: maps images and text into the same vector space\n",
        "* **ResNet embeddings**\n",
        "\n",
        "---\n",
        "\n",
        "## Using Embedding Functions in ChromaDB\n",
        "\n",
        "When you add documents or query texts to ChromaDB:\n",
        "\n",
        "* The embedding function **automatically converts** those texts into vectors.\n",
        "* Vectors are stored and indexed for similarity search.\n",
        "* You can also **use your own embedding function** if you prefer.\n",
        "\n",
        "---\n",
        "\n",
        "## Custom vs Built-in Embedding Functions\n",
        "\n",
        "| Aspect      | Built-in Embedding Function                    | Custom Embedding Function                   |\n",
        "| ----------- | ---------------------------------------------- | ------------------------------------------- |\n",
        "| Provided by | ChromaDB or underlying platform (OpenAI, etc.) | Your own ML model or third-party library    |\n",
        "| Usage       | Pass raw texts to `.add()` or `.query()`       | Precompute embeddings, then pass vectors    |\n",
        "| Flexibility | Easy to use, limited to available models       | Full control over embedding style & quality |\n",
        "| Performance | Usually optimized and maintained               | Depends on your model and resources         |\n",
        "\n",
        "---\n",
        "\n",
        "## Code Example: Using a Custom Embedding Function in ChromaDB (Python)\n",
        "\n",
        "```python\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "# Load OpenAI embedding function (built-in)\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(api_key=\"your_key\")\n",
        "\n",
        "# Create collection with custom embedding function\n",
        "collection = client.create_collection(\n",
        "    name=\"fruits\",\n",
        "    embedding_function=openai_ef\n",
        ")\n",
        "\n",
        "# Add documents â€” they get embedded automatically\n",
        "collection.add(\n",
        "    ids=[\"id1\"],\n",
        "    documents=[\"Pineapple is a tropical fruit.\"]\n",
        ")\n",
        "\n",
        "# Query with raw text â€” embedded automatically too\n",
        "results = collection.query(\n",
        "    query_texts=[\"Tell me about pineapple\"],\n",
        "    n_results=1\n",
        ")\n",
        "print(results)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Summary â€” What to remember about Embedding Functions\n",
        "\n",
        "* They **turn text/images into vectors** so machines can â€œunderstandâ€ meaning.\n",
        "* Vectors live in **high-dimensional space** where distance = similarity.\n",
        "* Embedding functions are **key components** in semantic search and AI apps.\n",
        "* You can **use built-in ones** or plug in your **custom models**.\n",
        "* ChromaDB integrates embedding functions seamlessly for indexing & querying.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-K9qvr09Ytdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = collection.query(\n",
        "    query_texts=[\"python\", \"fruit benefits\"],\n",
        "    n_results=2,\n",
        "    include=[ \"documents\", \"distances\", \"metadatas\"]\n",
        ")\n",
        "print(results)\n",
        "print(results[\"ids\"])  # IDs are always returned here\n",
        "print(results[\"documents\"])\n",
        "print(results[\"distances\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MAfTlU3Xh9K",
        "outputId": "e02730fa-32ed-4602-9232-9b222e367c1e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [['id2', 'id1'], ['id1', 'id2']], 'embeddings': None, 'documents': [['Lines of code in a large software project', 'Daily high temperatures for Tokyo, Japan from 1999â€“2024.'], ['Daily high temperatures for Tokyo, Japan from 1999â€“2024.', 'Lines of code in a large software project']], 'uris': None, 'included': ['documents', 'distances', 'metadatas'], 'data': None, 'metadatas': [[None, None], [None, None]], 'distances': [[1.5711636543273926, 1.923932433128357], [1.9816340208053589, 2.018092155456543]]}\n",
            "[['id2', 'id1'], ['id1', 'id2']]\n",
            "[['Lines of code in a large software project', 'Daily high temperatures for Tokyo, Japan from 1999â€“2024.'], ['Daily high temperatures for Tokyo, Japan from 1999â€“2024.', 'Lines of code in a large software project']]\n",
            "[[1.5711636543273926, 1.923932433128357], [1.9816340208053589, 2.018092155456543]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCWuw5b1Ymx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.trychroma.com/docs/overview/getting-started"
      ],
      "metadata": {
        "id": "sw4EINEVZt5d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "agegLufuZuQP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}